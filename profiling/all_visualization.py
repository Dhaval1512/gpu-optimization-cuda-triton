#!/usr/bin/env python3
"""
Ultimate Visualization Generator for JLR Hackathon
Generates ALL required tables and charts from your existing CSV data
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import os

# Professional styling
sns.set_style("whitegrid")
plt.rcParams['figure.dpi'] = 300
plt.rcParams['font.size'] = 11

class HackathonVisualizer:
    def __init__(self, report_dir="report", figures_dir="figures"):
        self.report_dir = Path(report_dir)
        self.figures_dir = Path(figures_dir)
        self.figures_dir.mkdir(exist_ok=True)
        
        print(f"\n{'='*80}")
        print(f"  JLR HACKATHON VISUALIZATION GENERATOR")
        print(f"{'='*80}\n")
        print(f"üìÅ Report directory: {self.report_dir}")
        print(f"üìÅ Figures directory: {self.figures_dir}\n")
    
    # ==================== UTILITY FUNCTIONS ====================
    
    def estimate_memory_mb(self, batch_size, feature_dim):
        """Estimate memory usage from tensor dimensions"""
        elements = batch_size * feature_dim
        bytes_used = elements * 4  # float32
        return bytes_used / (1024 * 1024)
    
    def calculate_throughput(self, batch_size, time_ms):
        """Calculate inference throughput"""
        if time_ms <= 0:
            return 0
        return (batch_size / time_ms) * 1000
    
    def estimate_gpu_efficiency(self, time_ms):
        """Rough GPU efficiency estimate based on execution time"""
        # Lower time = higher efficiency (simplified model)
        # Scale between 50-95%
        baseline = 0.3  # 0.3ms baseline for "perfect" efficiency
        efficiency = min(95, (baseline / max(time_ms, 0.01)) * 85)
        return max(50, efficiency)
    
    # ==================== TABLE GENERATION ====================
    
    def create_operation_table(self, op_name, cuda_time, triton_time, 
                                batch_size=128, feature_dim=512):
        """
        Create 4-metric comparison table for single operation
        """
        memory_mb = self.estimate_memory_mb(batch_size, feature_dim)
        
        data = {
            'Metric': [
                'Time (ms)',
                'Memory Usage (MB)',
                'Throughput (samples/sec)',
                'GPU Efficiency (%)'
            ],
            'CUDA': [
                f"{cuda_time:.4f}",
                f"{memory_mb:.2f}",
                f"{self.calculate_throughput(batch_size, cuda_time):.1f}",
                f"{self.estimate_gpu_efficiency(cuda_time):.1f}"
            ],
            'Triton': [
                f"{triton_time:.4f}",
                f"{memory_mb:.2f}",
                f"{self.calculate_throughput(batch_size, triton_time):.1f}",
                f"{self.estimate_gpu_efficiency(triton_time):.1f}"
            ]
        }
        
        df = pd.DataFrame(data)
        
        # Save CSV
        csv_path = self.report_dir / f"{op_name}_comparison_table.csv"
        df.to_csv(csv_path, index=False)
        
        # Calculate speedup
        speedup = cuda_time / triton_time if triton_time > 0 else 1.0
        winner = "CUDA" if speedup > 1 else "Triton"
        
        print(f"‚úÖ {op_name} table saved: {csv_path.name}")
        print(f"   Speedup: {abs(speedup):.2f}√ó ({winner} faster)\n")
        
        return df, speedup
    
    # ==================== CHART GENERATION ====================
    
    def create_scaling_chart(self, op_name, dimension_name, sizes, 
                             cuda_times, triton_times):
        """
        Create dual-panel scaling chart:
        - Left: Absolute performance
        - Right: Speedup analysis
        """
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
        
        # Panel 1: Absolute Times
        ax1.plot(sizes, cuda_times, 'o-', label='CUDA', 
                linewidth=2, markersize=8, color='#2E86AB')
        ax1.plot(sizes, triton_times, 's-', label='Triton', 
                linewidth=2, markersize=8, color='#A23B72')
        ax1.set_xlabel(dimension_name, fontsize=12, fontweight='bold')
        ax1.set_ylabel('Execution Time (ms)', fontsize=12, fontweight='bold')
        ax1.set_title(f'{op_name} - {dimension_name} Scaling', 
                     fontsize=14, fontweight='bold')
        ax1.legend(fontsize=11)
        ax1.grid(True, alpha=0.3)
        
        # Panel 2: Speedup
        speedups = [c / t if t > 0 else 1 for c, t in zip(cuda_times, triton_times)]
        colors = ['#27AE60' if s > 1 else '#E74C3C' for s in speedups]
        
        bars = ax2.bar(range(len(sizes)), speedups, color=colors, alpha=0.7)
        ax2.axhline(y=1.0, color='black', linestyle='--', linewidth=1.5, 
                   label='No Speedup', alpha=0.7)
        ax2.set_xticks(range(len(sizes)))
        ax2.set_xticklabels(sizes)
        ax2.set_xlabel(dimension_name, fontsize=12, fontweight='bold')
        ax2.set_ylabel('Speedup (CUDA / Triton)', fontsize=12, fontweight='bold')
        ax2.set_title(f'{op_name} - Speedup Analysis', 
                     fontsize=14, fontweight='bold')
        ax2.legend(fontsize=11)
        ax2.grid(True, alpha=0.3, axis='y')
        
        # Add value labels on bars
        for i, (bar, val) in enumerate(zip(bars, speedups)):
            ax2.text(i, val + 0.05, f'{val:.2f}√ó', 
                    ha='center', va='bottom', fontweight='bold', fontsize=10)
        
        plt.tight_layout()
        save_path = self.figures_dir / f"{op_name}_{dimension_name}_scaling.png"
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"‚úÖ Scaling chart saved: {save_path.name}")
        return save_path
    
    def create_fusion_comparison(self, fusion_data):
        """
        Create master fusion comparison chart
        
        Args:
            fusion_data: dict like {
                "Fusion 0\n(LN+GELU)": {"cuda": 0.61, "triton": 0.69},
                ...
            }
        """
        if not fusion_data:
            print("‚ö†Ô∏è  No fusion data provided")
            return
        
        fusion_names = list(fusion_data.keys())
        cuda_times = [fusion_data[f]['cuda'] for f in fusion_names]
        triton_times = [fusion_data[f]['triton'] for f in fusion_names]
        
        x = np.arange(len(fusion_names))
        width = 0.35
        
        fig, ax = plt.subplots(figsize=(12, 6))
        
        bars1 = ax.bar(x - width/2, cuda_times, width, 
                      label='CUDA', color='#3498DB', alpha=0.8)
        bars2 = ax.bar(x + width/2, triton_times, width, 
                      label='Triton', color='#E74C3C', alpha=0.8)
        
        ax.set_xlabel('Fusion Type', fontsize=12, fontweight='bold')
        ax.set_ylabel('Execution Time (ms)', fontsize=12, fontweight='bold')
        ax.set_title('Kernel Fusion Performance Comparison', 
                    fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(fusion_names, rotation=0, ha='center')
        ax.legend(fontsize=11)
        ax.grid(True, alpha=0.3, axis='y')
        
        # Add value labels
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{height:.3f}ms', ha='center', va='bottom', fontsize=9)
        
        plt.tight_layout()
        save_path = self.figures_dir / "all_fusions_comparison.png"
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"‚úÖ Fusion comparison chart saved: {save_path.name}\n")
        return save_path
    
    # ==================== MAIN GENERATION PIPELINE ====================
    
    def generate_from_workload_variations(self):
        """
        Generate visualizations from workload_variations.csv
        This contains EVERYTHING you need!
        """
        print(f"{'='*80}")
        print(f"  GENERATING VISUALIZATIONS FROM WORKLOAD DATA")
        print(f"{'='*80}\n")
        
        csv_path = self.report_dir / "workload_variations.csv"
        
        if not csv_path.exists():
            print(f"‚ùå {csv_path} not found!")
            return
        
        df = pd.read_csv(csv_path)
        print(f"‚úÖ Loaded {len(df)} rows from workload_variations.csv\n")
        
        # Get unique operations
        operations = df['operation'].unique()
        print(f"Operations found: {list(operations)}\n")
        
        all_tables = []
        
        for op in operations:
            print(f"{'='*80}")
            print(f"  Processing: {op.upper()}")
            print(f"{'='*80}\n")
            
            op_data = df[df['operation'] == op]
            
            # Get average times for table generation
            cuda_avg = op_data[op_data['implementation'] == 'cuda']['mean_ms'].mean()
            triton_avg = op_data[op_data['implementation'] == 'triton']['mean_ms'].mean()
            
            # Create comparison table
            table_df, speedup = self.create_operation_table(
                op, cuda_avg, triton_avg
            )
            all_tables.append({
                'Operation': op,
                'CUDA_Time_ms': cuda_avg,
                'Triton_Time_ms': triton_avg,
                'Speedup': speedup,
                'Winner': 'CUDA' if speedup > 1 else 'Triton'
            })
            
            # Generate scaling charts for batch_size
            print(f"  Generating Batch Size Scaling Chart...")
            batch_sizes = sorted(op_data['batch_size'].unique())
            
            cuda_batch_times = []
            triton_batch_times = []
            
            for bs in batch_sizes:
                cuda_time = op_data[
                    (op_data['implementation'] == 'cuda') & 
                    (op_data['batch_size'] == bs)
                ]['mean_ms'].mean()
                
                triton_time = op_data[
                    (op_data['implementation'] == 'triton') & 
                    (op_data['batch_size'] == bs)
                ]['mean_ms'].mean()
                
                cuda_batch_times.append(cuda_time)
                triton_batch_times.append(triton_time)
            
            self.create_scaling_chart(
                op, "Batch_Size", batch_sizes,
                cuda_batch_times, triton_batch_times
            )
            
            # Generate scaling charts for hidden_dim
            print(f"  Generating Hidden Dimension Scaling Chart...")
            hidden_dims = sorted(op_data['hidden_dim'].unique())
            
            cuda_dim_times = []
            triton_dim_times = []
            
            for dim in hidden_dims:
                cuda_time = op_data[
                    (op_data['implementation'] == 'cuda') & 
                    (op_data['hidden_dim'] == dim)
                ]['mean_ms'].mean()
                
                triton_time = op_data[
                    (op_data['implementation'] == 'triton') & 
                    (op_data['hidden_dim'] == dim)
                ]['mean_ms'].mean()
                
                cuda_dim_times.append(cuda_time)
                triton_dim_times.append(triton_time)
            
            self.create_scaling_chart(
                op, "Hidden_Dimension", hidden_dims,
                cuda_dim_times, triton_dim_times
            )
            
            print()
        
        # Create master summary table
        print(f"{'='*80}")
        print(f"  CREATING MASTER SUMMARY TABLE")
        print(f"{'='*80}\n")
        
        summary_df = pd.DataFrame(all_tables)
        summary_path = self.report_dir / "master_summary_table.csv"
        summary_df.to_csv(summary_path, index=False)
        
        print(f"‚úÖ Master summary saved: {summary_path.name}\n")
        print(summary_df.to_string(index=False))
        print()
    
    def generate_fusion_visualizations(self):
        """
        Generate fusion-specific visualizations
        """
        print(f"{'='*80}")
        print(f"  GENERATING FUSION VISUALIZATIONS")
        print(f"{'='*80}\n")
        
        # Load fusion benchmark CSVs
        fusion_files = {
            "Fusion 0\n(LN+GELU)": "baseline_kernels_benchmarks.csv",
            "Fusion 1\n(GELU+Swish)": "fusion_swiss_gelu_kernels_benchmarks.csv",
            "Fusion 2\n(LN+Swish+Dropout)": "fusion_ln_swiss_dropout_kernel_benchmarks.csv",
            "Fusion 3\n(LN+GELU+Swish)": "fusion_ln_swiss_gelu_kernels_benchmarks.csv"
        }
        
        fusion_data = {}
        
        for fusion_name, csv_file in fusion_files.items():
            csv_path = self.report_dir / csv_file
            
            if not csv_path.exists():
                print(f"‚ö†Ô∏è  {csv_file} not found, skipping {fusion_name}")
                continue
            
            df = pd.read_csv(csv_path)
            
            # Get average times for CUDA and Triton
            if 'fused' in csv_file or 'fusion' in csv_file:
                cuda_time = df[df['implementation'].str.contains('cuda', case=False, na=False)]['mean_ms'].mean()
                triton_time = df[df['implementation'].str.contains('triton', case=False, na=False)]['mean_ms'].mean()
            else:
                # For kernel_benchmarks.csv (Fusion 0)
                cuda_time = df[(df['kernel'] == 'fused_ln_gelu') & (df['implementation'] == 'cuda')]['mean_ms'].mean()
                triton_time = df[(df['kernel'] == 'fused_ln_gelu') & (df['implementation'] == 'triton')]['mean_ms'].mean()
            
            fusion_data[fusion_name] = {
                'cuda': cuda_time,
                'triton': triton_time
            }
            
            print(f"‚úÖ {fusion_name}: CUDA={cuda_time:.3f}ms, Triton={triton_time:.3f}ms")
        
        print()
        
        # Create fusion comparison chart
        if fusion_data:
            self.create_fusion_comparison(fusion_data)
    
    def generate_cnn_inference_chart(self):
        """
        Generate CNN inference comparison (Fusion 3)
        """
        print(f"{'='*80}")
        print(f"  GENERATING CNN INFERENCE VISUALIZATION")
        print(f"{'='*80}\n")
        
        csv_path = self.report_dir / "fusion_ln_swiss_gelu_cnn_inference.csv"
        
        if not csv_path.exists():
            print(f"‚ö†Ô∏è  {csv_path} not found")
            return
        
        df = pd.read_csv(csv_path)
        
        # Group by batch size
        batch_sizes = sorted(df['batch_size'].unique())
        
        pytorch_times = []
        cuda_times = []
        triton_times = []
        
        for bs in batch_sizes:
            pytorch_times.append(
                df[(df['implementation'] == 'pytorch_unfused') & 
                   (df['batch_size'] == bs)]['mean_ms'].mean()
            )
            cuda_times.append(
                df[(df['implementation'] == 'cuda_fused') & 
                   (df['batch_size'] == bs)]['mean_ms'].mean()
            )
            triton_times.append(
                df[(df['implementation'] == 'triton_fused') & 
                   (df['batch_size'] == bs)]['mean_ms'].mean()
            )
        
        # Create chart
        fig, ax = plt.subplots(figsize=(12, 6))
        
        x = np.arange(len(batch_sizes))
        width = 0.25
        
        ax.bar(x - width, pytorch_times, width, label='PyTorch Unfused', 
              color='#95A5A6', alpha=0.8)
        ax.bar(x, cuda_times, width, label='CUDA Fused', 
              color='#3498DB', alpha=0.8)
        ax.bar(x + width, triton_times, width, label='Triton Fused', 
              color='#E74C3C', alpha=0.8)
        
        ax.set_xlabel('Batch Size', fontsize=12, fontweight='bold')
        ax.set_ylabel('Inference Time (ms/batch)', fontsize=12, fontweight='bold')
        ax.set_title('Fusion 3 CNN Inference Performance', 
                    fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(batch_sizes)
        ax.legend(fontsize=11)
        ax.grid(True, alpha=0.3, axis='y')
        
        plt.tight_layout()
        save_path = self.figures_dir / "fusion3_cnn_inference.png"
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"‚úÖ CNN inference chart saved: {save_path.name}\n")
    
    def generate_gpu_profiling_summary(self):
        """
        Generate GPU profiling summary table and visualization
        """
        print(f"{'='*80}")
        print(f"  GENERATING GPU PROFILING SUMMARY")
        print(f"{'='*80}\n")
        
        csv_path = self.report_dir / "gpu_kernel_profiling.csv"
        
        if not csv_path.exists():
            print(f"‚ö†Ô∏è  {csv_path} not found")
            return
        
        df = pd.read_csv(csv_path)
        
        # Display summary
        print("GPU Profiling Metrics:")
        print(df.to_string(index=False))
        print()
        
        # Create visualization
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 10))
        
        operations = df['Operation'].tolist()
        
        # Plot 1: Compute Throughput
        ax1.barh(operations, df['Compute_Throughput_%'], color='#3498DB', alpha=0.8)
        ax1.set_xlabel('Compute Throughput (%)', fontweight='bold')
        ax1.set_title('GPU Compute Utilization', fontweight='bold')
        ax1.grid(True, alpha=0.3, axis='x')
        
        # Plot 2: Memory Throughput
        ax2.barh(operations, df['Memory_Throughput_%'], color='#E74C3C', alpha=0.8)
        ax2.set_xlabel('Memory Throughput (%)', fontweight='bold')
        ax2.set_title('Memory Bandwidth Utilization', fontweight='bold')
        ax2.grid(True, alpha=0.3, axis='x')
        
        # Plot 3: Occupancy
        ax3.barh(operations, df['Occupancy_%'], color='#27AE60', alpha=0.8)
        ax3.set_xlabel('Occupancy (%)', fontweight='bold')
        ax3.set_title('GPU Occupancy', fontweight='bold')
        ax3.grid(True, alpha=0.3, axis='x')
        
        # Plot 4: SM Efficiency
        ax4.barh(operations, df['SM_Efficiency_%'], color='#F39C12', alpha=0.8)
        ax4.set_xlabel('SM Efficiency (%)', fontweight='bold')
        ax4.set_title('Streaming Multiprocessor Efficiency', fontweight='bold')
        ax4.grid(True, alpha=0.3, axis='x')
        
        plt.tight_layout()
        save_path = self.figures_dir / "gpu_profiling_metrics.png"
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"‚úÖ GPU profiling visualization saved: {save_path.name}\n")
    
    def run_all(self):
        """
        Generate ALL visualizations
        """
        print(f"\n{'='*80}")
        print(f"  üöÄ STARTING COMPLETE VISUALIZATION GENERATION")
        print(f"{'='*80}\n")
        
        # 1. Workload variations (baseline ops)
        self.generate_from_workload_variations()
        
        # 2. Fusion visualizations
        self.generate_fusion_visualizations()
        
        # 3. CNN inference
        self.generate_cnn_inference_chart()
        
        # 4. GPU profiling
        self.generate_gpu_profiling_summary()
        
        print(f"\n{'='*80}")
        print(f"  ‚úÖ ALL VISUALIZATIONS GENERATED SUCCESSFULLY!")
        print(f"{'='*80}\n")
        print(f"üìä Tables saved to: {self.report_dir}/")
        print(f"üìà Charts saved to: {self.figures_dir}/\n")


def main():
    visualizer = HackathonVisualizer()
    visualizer.run_all()


if __name__ == "__main__":
    main()